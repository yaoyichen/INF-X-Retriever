<h1 align="center">âš¡ INF-X-Retriever</h1>

<p align="center">
  <strong>A Pragmatic & General Solution for Reasoning-Intensive Retrieval</strong>
</p>

<p align="center">
  <a href="https://brightbenchmark.github.io/"><img src="https://img.shields.io/badge/BRIGHT_Benchmark-Rank_1st-8A2BE2" alt="Rank"></a>
  <a href="https://huggingface.co/infly/inf-query-aligner"><img src="https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-INF--Query--Aligner-blue" alt="Hugging Face"></a>
  <a href="https://huggingface.co/infly/inf-retriever-v1-pro"><img src="https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-INF--Retriever-yellow" alt="Hugging Face"></a>
  <a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License"></a>
</p>

<p align="center">
  <strong>INF-X-Retriever</strong> is a production-grade dense reasoning retrieval framework developed by <strong>Infinite Light Years (INF)</strong>.<br>
  It delivers robust retrieval performance across arbitrary task databases (<mathcal>X</mathcal>) with minimal supervision, emphasizing industrial deployability and reasoning depth over architectural complexity.
</p>

<p align="center">
  <a href="#-introduction">Introduction</a> â€¢
  <a href="#-philosophy--methodology">Philosophy</a> â€¢
  <a href="#-performance">Performance</a> â€¢
  <a href="#-models">Models</a> â€¢
  <a href="#-citation">Citation</a>
</p>

---

## ğŸ“– Introduction

The advent of Large Language Models (LLMs) has fundamentally transformed information retrieval paradigms.

* **Pre-LLM Era:** Users issued concise, keyword-driven queries optimized for lexical matching.
* **LLM Era:** Users engage with retrieval systems as reasoning agents. Queries now encompass contextual narratives, explicit constraints, and structured formatting requirementsâ€”elements that constitute semantic noise for conventional retrieval architectures.

Addressing this evolution demands retrieval systems capable of sophisticated intent distillation from verbally complex inputs. **INF-X-Retriever** is purpose-built for this challenge. We validate our methodology on the **BRIGHT Benchmark**, a curated dataset reflecting real-world query complexity that necessitates reasoning-intensive document matching.

---

## ğŸ’¡ Design Philosophy

Our methodology is rooted in **Engineering Pragmatism** and **First Principles Reasoning**. While competitive solutions on the BRIGHT leaderboard gravitate toward elaborate multi-stage architectures, we pursue a fundamentally different trajectoryâ€”one that prioritizes **production readiness**, **architectural coherence**, and **computational parsimony**. 

> ğŸ¯ **Core Principle:** *"Less is More"* â€” Maximal efficacy through deliberate minimalism.

### ğŸš« No Rerankers

**Rationale:** *Architectural redundancy in RAG workflows*

Reranking stages introduce non-trivial latency and computational overhead while yielding diminishing returns. Given that downstream RAG systems invariably employ an LLM for answer synthesis, this component inherently performs context discriminationâ€”rendering explicit reranking architecturally superfluous.

**Trade-off:** We sacrifice marginal ranking precision for substantial improvements in inference throughput and operational efficiency.

### ğŸš« No HyDE

**Rationale:** *Epistemological inconsistency with RAG objectives*

Hypothetical Document Embeddings (HyDE) leverage LLMs to synthesize idealized answers, subsequently retrieving semantically proximate documents. This methodology embodies a fundamental logical contradiction:
- **If the LLM possesses domain knowledge** â†’ Retrieval augmentation becomes obsolete
- **If the LLM lacks domain knowledge** â†’ Synthesized hypotheses constitute hallucinated artifacts

While HyDE demonstrates benchmark efficacy (leveraging training data overlap), it **fundamentally fails in out-of-distribution domains**â€”precisely the scenarios for which RAG architectures are engineered.

### âš¡ Radical Simplicity

**Rationale:** *Architectural complexity constitutes operational debt*

We systematically eschew conventional techniques that introduce deployment fragility:

- **No sparse retrieval** (e.g., BM25) â€” Eliminates hybrid fusion complexity and hyperparameter sensitivity
- **No multi-query expansion** â€” Single-pass alignment minimizes inference latency
- **No ensemble methods** â€” Monolithic robustness supersedes fragile model combinations

**Result:** A system that is **operationally streamlined**, **latency-optimized**, and **diagnostically transparent** in production deployments.

---

## ğŸ› ï¸ Architecture

Our system comprises two tightly integrated components:

### ğŸ” Query Aligner
* **Model:** [ğŸ¤— infly/inf-query-aligner](https://huggingface.co/infly/inf-query-aligner)
* **Method:** Reinforcement Learning fine-tuning on [**Qwen2.5-7B-instruct**](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct) foundation.
* **Function:** Performs semantic intent distillation from verbally complex queries. Executes pure **Query Alignment**â€”eliminating extraneous formatting directives and contextual noise to extract core retrieval intentâ€”explicitly avoiding hypothetical document generation.

### ğŸš€ Retriever
* **Model:** [ğŸ¤— infly/inf-retriever-v1-pro](https://huggingface.co/infly/inf-retriever-v1-pro)
* **Method:** Continual training on the general-purpose [**inf-retriever-v1**](https://huggingface.co/infly/inf-retriever-v1) backbone with targeted long-query adaptation.
* **Function:** A generalized dense retrieval architecture resistant to depth-specific overfitting, ensuring robust cross-task transferability.

---

## ğŸ† Performance

As of **November 20, 2025**, INF-X-Retriever holds the **No. 1 position** on the [BRIGHT Benchmark](https://brightbenchmark.github.io/).

| Model | **Avg** | Biology | Earth Sci | Economics | Psychology | Robotics | StackOverflow | LeetCode | TheoremQA (T) |
|:---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| **INF-X-Retriever** | **55.04** | **0.661** | **0.628** | **0.518** | **0.611** | 0.406 | **0.512** | **0.454** | **0.593** |
| BGE-Reasoner-0928 | 46.40 | 0.685 | 0.664 | 0.406 | 0.531 | **0.432** | 0.441 | 0.290 | 0.583 |
| DIVER (v2) | 45.80 | 0.680 | 0.625 | 0.420 | 0.582 | 0.415 | 0.443 | 0.348 | 0.526 |

---

## ğŸ“¥ Models

We have released both components as open-source artifacts to facilitate community research and development.

* **Aligner:** [ğŸ¤— infly/inf-query-aligner](https://huggingface.co/infly/inf-query-aligner)
* **Retriever:** [ğŸ¤— infly/inf-retriever-v1-pro](https://huggingface.co/infly/inf-retriever-v1-pro)

---

## ğŸ–Šï¸ Citation

If INF-X-Retriever contributes to your research or production systems, please cite our work:

```bibtex
@misc{yao2025infx,
    title        = {INF-X-Retriever},
    author       = {Yichen Yao and Jiahe Wan and Yuxin Hong and Mengna Zhang and Junhan Yang and Yinhui Xu and Wei Chu and Yuan Qi},
    year         = {2025},
    url          = {https://yaoyichen.github.io/INF-X-Retriever/},
    note         = {GitHub repository}
}
```
